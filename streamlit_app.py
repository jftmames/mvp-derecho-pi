import streamlit as st
import pandas as pd
import json
import graphviz

# Intentamos importar weasyprint para PDF; si no est√°, lo ignoramos
try:
    from weasyprint import HTML
except ImportError:
    HTML = None

# --- IMPORTS DE M√ìDULOS PROPIOS ---
from cd_modules.core.extractor_conceptual import extraer_conceptos
from cd_modules.core.inquiry_engine import InquiryEngine
from cd_modules.core.contextual_generator import generar_contexto
from cd_modules.core.pathrag_pi import recuperar_fragmentos

# --- CONFIGURACI√ìN INICIAL ---
st.set_page_config(page_title="Demo PI - C√≥digo Deliberativo", layout="wide")
st.title("üìö Demo MVP - Derecho de la Propiedad Intelectual")
st.markdown("Esta demo simula razonamiento jur√≠dico automatizado, con validaci√≥n epist√©mica visible.")

# --- GU√çA PARA EL EVALUADOR ANECA ---
with st.expander("‚ÑπÔ∏è Gu√≠a para el Evaluador (ANECA) - Haga clic para expandir"):
    st.markdown(
        """
        **Bienvenido/a al MVP del C√≥digo Deliberativo para el Derecho de la Propiedad Intelectual.**

        Esta demostraci√≥n ha sido dise√±ada para ilustrar nuestra aproximaci√≥n computacional a la organizaci√≥n del juicio y el razonamiento jur√≠dico.

        **1. Prop√≥sito del MVP:**
        * Demostrar c√≥mo el C√≥digo Deliberativo estructura una consulta compleja en preguntas jer√°rquicas.
        * Mostrar la recuperaci√≥n de contexto legal (simulada v√≠a PathRAG) para cada subpregunta.
        * Evidenciar la **validaci√≥n epist√©mica** (indicada por los 'badges' ‚úÖ‚ö†Ô∏è‚ùå) y la **trazabilidad** del proceso.

        **2. Innovaci√≥n Clave:**
        * A diferencia de los modelos generativos que buscan una respuesta √∫nica, este sistema **organiza la deliberaci√≥n**, mantiene m√∫ltiples l√≠neas de indagaci√≥n y hace el proceso **auditable y justificable**. No genera 'la' respuesta, sino que *estructura el pensamiento*.

        **3. Mapa del MVP y Flujo Sugerido:**
        * **Configuraci√≥n (Barra Lateral):** Introduzca su pregunta o seleccione un ejemplo. Ajuste la profundidad/anchura si lo desea. Pruebe el bot√≥n **"üóëÔ∏è Reiniciar Deliberaci√≥n"**.
        * **Conceptos y Fragmentos:** Observe los conceptos clave y los fragmentos legales (ahora en columnas).
        * **√Årbol de Razonamiento:** Explore el **grafo visual** y luego la **vista de texto** (en el expander) para generar contexto con **spinners** de feedback.
        * **Validaci√≥n:** F√≠jese en los 'badges' (con tooltips) junto a cada nodo respondido.
        * **Reasoning Tracker:** Revise las **m√©tricas** y la tabla inferior. Descargue el informe.

        **4. Estado Actual (Transparencia):**
        * Este es un **Producto M√≠nimo Viable (MVP)**.
        * El `Inquiry Engine` y `Contextual Generator` (con validaci√≥n) est√°n implementados.
        * La recuperaci√≥n de fragmentos (`PathRAG`) y el `Epistemic Navigator` (b√∫squeda) son **simulaciones (stubs)** para demostrar el flujo.
        * El `Adaptive Dialogue` es un **placeholder** futuro.
        * El EEE es una **m√©trica simplificada** en esta fase.

        **¬°Gracias por su tiempo y evaluaci√≥n!**
        """,
        unsafe_allow_html=True
    )
# --- FIN GU√çA ---

# --- CACHES PARA MEJORAR RENDIMIENTO ---
@st.cache_data(show_spinner="Extrayendo conceptos...")
def get_conceptos(pregunta: str):
    return extraer_conceptos(pregunta)

@st.cache_data(show_spinner="Recuperando fragmentos...")
def get_fragmentos(pregunta: str, top_k: int = 3):
    return recuperar_fragmentos(pregunta, top_k)

@st.cache_data(show_spinner="Generando √°rbol de razonamiento...")
def get_tree(pregunta: str, max_depth: int, max_width: int):
    ie = InquiryEngine(pregunta, max_depth=max_depth, max_width=max_width)
    return ie.generate()

# --- DECLARACI√ìN DE VALOR ---
st.markdown(
    """
    ### ‚úÖ Este MVP Cumple con:
    - **Dominio PI especializaci√≥n**: Respuestas limitadas a propiedad intelectual.
    - **Ontolog√≠a PI**: Mapeo de conceptos y visualizaci√≥n de grafo.
    - **Corpus legal validado**: Uso de fuentes oficiales (simulado).
    - **Pipeline especializado**: PathRAG, validaci√≥n epist√©mica.
    - **Trazabilidad total**: Registro de pasos, fuentes y validaci√≥n, exportable.
    - **Explicabilidad**: Badge de validaci√≥n y detallado del razonamiento.
    """,
    unsafe_allow_html=True
)

# --- SIDEBAR: INPUTS DEL USUARIO ---
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del √°rbol")

# Campo para la clave de API de OpenAI
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password", help="Introduce tu clave de API de OpenAI para activar la generaci√≥n de contexto.")

pregunta_input = st.sidebar.text_input("Pregunta principal", "¬øQui√©n puede ser autor de una obra?")
max_depth = st.sidebar.slider("Profundidad", 1, 3, 2)
max_width = st.sidebar.slider("Anchura", 1, 4, 2)
example = st.sidebar.selectbox(
    "Ejemplos de consulta",
    ["Ninguno", "Patente software IA", "Marca sonora Espa√±a", "Convenios internacionales derechos autor"]
)

if example != "Ninguno":
    templates = {
        "Patente software IA": "¬øEs patentable un software de IA para reconocimiento de voz en Espa√±a?",
        "Marca sonora Espa√±a": "¬øQu√© protecci√≥n tiene una marca sonora registrada en Espa√±a?",
        "Convenios internacionales derechos autor": "¬øQu√© convenios internacionales regulan el derecho de autor en Espa√±a?"
    }
    pregunta = templates[example]
else:
    pregunta = pregunta_input

# --- EJECUCI√ìN DEL PIPELINE ---
conceptos = get_conceptos(pregunta)
frags = get_fragmentos(pregunta, top_k=3)
tree = get_tree(pregunta, max_depth, max_width)

# --- Sesi√≥n para tracker ---
if "tracker" not in st.session_state:
    st.session_state.tracker = []
if "last_question" not in st.session_state:
    st.session_state.last_question = ""

# Limpiar tracker si la pregunta cambia
if pregunta != st.session_state.last_question:
    st.session_state.tracker = []
    st.session_state.last_question = pregunta


# --- Funciones Auxiliares ---
def badge_validacion(tipo):
    """Genera un badge HTML con tooltip para el estado de validaci√≥n."""
    if tipo == "validada":
        return '<span style="color: white; background-color: #28a745; padding: 3px 8px; border-radius: 6px;" title="‚úÖ Validada: La respuesta tiene un respaldo legal claro y directo en las fuentes.">‚úÖ Validada</span>'
    elif tipo == "parcial":
        return '<span style="color: black; background-color: #ffc107; padding: 3px 8px; border-radius: 6px;" title="‚ö†Ô∏è Parcial: La respuesta se basa en una interpretaci√≥n o fuente indirecta.">‚ö†Ô∏è Parcial</span>'
    else:
        return '<span style="color: white; background-color: #dc3545; padding: 3px 8px; border-radius: 6px;" title="‚ùå No validada: No se encontr√≥ respaldo claro en las fuentes consultadas.">‚ùå No validada</span>'

def esta_respondido(nodo):
    return any(x["Subpregunta"] == nodo for x in st.session_state.tracker)

def contar_nodos(tree):
    total = 0
    def contar(hijos):
        nonlocal total
        for nodo, subhijos in hijos.items():
            total += 1
            contar(subhijos)
    for raiz, hijos in tree.items():
        total += 1
        contar(hijos)
    return total

def contar_respondidos():
    return len(st.session_state.tracker)

def generar_todo(tree, api_key):
    if not api_key:
        st.error("Por favor, introduce una clave de API de OpenAI para generar el contexto.")
        return
    with st.spinner("Generando contexto para TODOS los nodos con OpenAI..."):
        def gen(hijos):
            for nodo, subhijos in hijos.items():
                if not esta_respondido(nodo):
                    data = generar_contexto(nodo, openai_api_key=api_key)
                    st.session_state.tracker.append({
                        "Subpregunta": nodo,
                        "Contexto": data["contexto"],
                        "Fuente": data["fuente"],
                        "Validaci√≥n": data.get("validacion", "no validada")
                    })
                gen(subhijos)
        for raiz, hijos in tree.items():
            if not esta_respondido(raiz):
                data = generar_contexto(raiz, openai_api_key=api_key)
                st.session_state.tracker.append({
                    "Subpregunta": raiz,
                    "Contexto": data["contexto"],
                    "Fuente": data["fuente"],
                    "Validaci√≥n": data.get("validacion", "no validada")
                })
            gen(hijos)
    st.rerun()

# --- Funciones para Grafo (Versi√≥n Graphviz) ---
def get_node_color(nodo):
    """Obtiene el color del nodo seg√∫n su estado de validaci√≥n."""
    data = next((x for x in st.session_state.tracker if x["Subpregunta"] == nodo), None)
    if data:
        val = data.get("Validaci√≥n", "no validada")
        if val == "validada": return "#D4EDDA"
        elif val == "parcial": return "#FFF3CD"
        else: return "#F8D7DA"
    return "#E9ECEF"

def get_node_font_color(nodo):
    """Obtiene el color de la fuente para mejor contraste."""
    data = next((x for x in st.session_state.tracker if x["Subpregunta"] == nodo), None)
    if data:
        val = data.get("Validaci√≥n", "no validada")
        if val == "validada": return "#155724"
        elif val == "parcial": return "#856404"
        else: return "#721c24"
    return "#495057"

def construir_grafo_gv(tree_dict, dot):
    """Funci√≥n recursiva para construir el grafo Graphviz."""
    for parent, children in tree_dict.items():
        dot.node(parent, parent, shape='box', style='filled',
                 fillcolor=get_node_color(parent),
                 fontcolor=get_node_font_color(parent),
                 fontname="Arial", fontsize="10")
        for child, sub_children in children.items():
            dot.node(child, child, shape='box', style='filled',
                     fillcolor=get_node_color(child),
                     fontcolor=get_node_font_color(child),
                     fontname="Arial", fontsize="10")
            dot.edge(parent, child, color="#6c757d")
            construir_grafo_gv({child: sub_children}, dot)

def mostrar_grafo(tree):
    """Prepara y muestra el grafo con Graphviz."""
    dot = graphviz.Digraph(comment='√Årbol de Razonamiento')
    dot.attr(rankdir='TB')
    dot.attr('node', shape='box', style='filled', fontname="Arial", fontsize="10")
    dot.attr('edge', color="#6c757d")
    construir_grafo_gv(tree, dot)
    if dot.body:
        st.graphviz_chart(dot, use_container_width=True)
        st.caption("Este es un grafo est√°tico. Use la vista de texto inferior para interactuar.")
    else:
        st.info("El √°rbol de razonamiento est√° vac√≠o.")

# --- BOT√ìN DE REINICIO ---
st.sidebar.markdown("---")
if st.sidebar.button("üóëÔ∏è Reiniciar Deliberaci√≥n"):
    st.session_state.tracker = []
    st.rerun()

# --- Renderizado de la App ---
st.divider()

col_izq, col_der = st.columns(2)
with col_izq:
    st.subheader("üß© Conceptos extra√≠dos (NLP)")
    st.write(conceptos or "‚Äî")

with col_der:
    st.subheader("üîç Fragmentos recuperados (PathRAG)")
    st.caption("Estos son ejemplos de fragmentos recuperados por nuestro sistema PathRAG (actualmente simulado).")
    if frags:
        for f in frags:
            with st.expander(f["titulo"]):
                st.markdown(f"> {f['fragmento']}")
                st.markdown(f"[Ver fuente]({f['url']})")
    else:
        st.info("No se recuperaron fragmentos relevantes.")

st.divider()
st.subheader("üå≥ √Årbol de Razonamiento Jur√≠dico")
mostrar_grafo(tree)

# --- MOSTRAR DETALLES Y ACCIONES (VISTA TEXTO) ---
with st.expander("üîç Ver Detalles y Generar Contexto (Vista de Texto)"):
    for raiz, hijos in tree.items():
        # APLICADA LA CORRECCI√ìN AQU√ç:
        # La funci√≥n ahora acepta un 'path_prefix' para crear claves √∫nicas.
        def mostrar_detalle(nodo, sub, nivel=0, path_prefix=""):
            margen = "‚ÄÉ‚ÄÉ" * nivel
            # Creamos una ruta √∫nica para el nodo actual. Usamos hash para acortar la clave.
            current_path = f"{path_prefix}_{hash(nodo)}"
            
            data = next((x for x in st.session_state.tracker if x["Subpregunta"] == nodo), None)
            with st.container():
                c1, c2 = st.columns([0.9, 0.1])
                c1.markdown(f"{margen}üîπ **{nodo}**")
                if data:
                    c2.markdown(badge_validacion(data["Validaci√≥n"]), unsafe_allow_html=True)
                st.markdown(f"{margen}---")
                if data:
                    st.info(f"{margen}üìò *{data['Contexto']}*")
                    fuente_texto = data.get('Fuente', '')
                    if fuente_texto and fuente_texto.startswith("http"):
                        st.markdown(f"{margen}üîó **Fuente:** [{fuente_texto}]({fuente_texto})")
                    elif fuente_texto:
                        st.markdown(f"{margen}üîó **Fuente:** {fuente_texto}")
                else:
                    # Usamos la nueva ruta √∫nica para la clave del bot√≥n.
                    if st.button(f"üß† Generar contexto", key=f"gen_{current_path}", disabled=not openai_api_key):
                        with st.spinner(f"Generando contexto para '{nodo}' con OpenAI..."):
                            nuevo = generar_contexto(nodo, openai_api_key=openai_api_key)
                            st.session_state.tracker.append({
                                "Subpregunta": nodo,
                                "Contexto": nuevo["contexto"],
                                "Fuente": nuevo["fuente"],
                                "Validaci√≥n": nuevo.get("validacion","no validada")
                            })
                        st.rerun()
                st.markdown(f"{margen}---")
            
            # Pasamos el nuevo prefijo de ruta a las llamadas recursivas.
            for h, s in sub.items():
                mostrar_detalle(h, s, nivel+1, path_prefix=current_path)
        
        # La llamada inicial comienza con la ra√≠z.
        mostrar_detalle(raiz, hijos, nivel=0, path_prefix="root")

st.divider()

# Barra de progreso y bot√≥n global
total = contar_nodos(tree)
resp = contar_respondidos()
colp, colb = st.columns([6,4])
ratio = resp/total if total else 0
colp.progress(min(max(ratio, 0.0), 1.0), text=f"Progreso: {resp}/{total}")
colb.button("üß† Generar TODO el contexto", on_click=generar_todo, args=(tree, openai_api_key), type="primary", use_container_width=True, disabled=not openai_api_key)

st.divider()

# Tracker, M√©tricas y Descargas
st.subheader("üìä Reasoning Tracker y M√©tricas")
if resp > 0:
    df = pd.DataFrame(st.session_state.tracker)
    validada_count = df[df["Validaci√≥n"] == "validada"].shape[0]
    parcial_count = df[df["Validaci√≥n"] == "parcial"].shape[0]
    eee_score = ((validada_count + parcial_count) / resp * 100) if resp > 0 else 0
    st.markdown("#### Resumen del Proceso Deliberativo:")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Nodos Totales", f"{total}")
    col2.metric("Nodos Respondidos", f"{resp} ({resp/total:.0%})")
    col3.metric("Validados (‚úÖ + ‚ö†Ô∏è)", f"{validada_count + parcial_count}")
    col4.metric("EEE (Simplificado)", f"{eee_score:.1f}%",
                help="√çndice de Equilibrio Erot√©tico (Simplificado): % de nodos respondidos con respaldo 'Validado' o 'Parcial'. Mide la robustez epist√©mica alcanzada.")

    with st.expander("üìò ¬øQu√© es el √çndice de Equilibrio Erot√©tico (EEE)?"):
        st.markdown(
            """
            El **√çndice de Equilibrio Erot√©tico (EEE)** es una m√©trica para evaluar la **calidad deliberativa** de un proceso de razonamiento. No mide si una IA 'acierta', sino *c√≥mo* razona.

            En su versi√≥n completa (descrita en la teor√≠a), eval√∫a 5 dimensiones: Profundidad, Pluralidad, Justificaci√≥n, Revisi√≥n y Trazabilidad.

            **En este MVP, presentamos una versi√≥n simplificada:**
            * **EEE (Simplificado) = (% de Nodos Respondidos que son '‚úÖ Validada' o '‚ö†Ô∏è Parcial')**
            * Nos da una idea r√°pida de qu√© proporci√≥n del razonamiento generado tiene un respaldo (aunque sea indirecto) en las fuentes simuladas.
            * Un EEE m√°s alto sugiere un razonamiento m√°s fundamentado seg√∫n nuestro `validador_epistemico.py`.

            *Aunque la clase `ReasoningTracker` existe, este c√°lculo se realiza aqu√≠ para mayor claridad en el MVP.*
            """
        )

    st.markdown("#### Detalle del Reasoning Tracker:")
    st.dataframe(df, use_container_width=True)
    st.markdown("#### Opciones de Exportaci√≥n:")
    csv = df.to_csv(index=False).encode('utf-8')
    md_content = "# Informe de Razonamiento\n" + "\n".join(
        f"- **{r['Subpregunta']}**: {r['Contexto']} (Fuente: {r['Fuente']}, Val: {r['Validaci√≥n']})"
        for r in st.session_state.tracker
    )
    md = md_content.encode('utf-8')
    js = json.dumps(st.session_state.tracker, indent=2, ensure_ascii=False).encode('utf-8')
    d_col1, d_col2, d_col3, d_col4 = st.columns(4)
    d_col1.download_button("üì• CSV", data=csv, file_name="tracker.csv", mime="text/csv", use_container_width=True)
    d_col2.download_button("üì• MD", data=md, file_name="informe.md", mime="text/markdown", use_container_width=True)
    d_col3.download_button("üì• JSON", data=js, file_name="logs.json", mime="application/json", use_container_width=True)

    if HTML:
        html_content = "<html><head><meta charset='UTF-8'></head><body>" + md_content.replace("\n","<br>") + "</body></html>"
        pdf = HTML(string=html_content).write_pdf()
        d_col4.download_button("üì• PDF", data=pdf, file_name="informe.pdf", mime="application/pdf", use_container_width=True)
    else:
        d_col4.info("PDF no disponible (falta WeasyPrint)")

else:
    st.info("A√∫n no hay pasos registrados. Genere contexto para alg√∫n nodo del √°rbol.")

st.divider()

# Ayudas
with st.expander("üìò ¬øQu√© es la validaci√≥n epist√©mica?"):
    st.markdown(
        """
        - ‚úÖ Validada: respaldo legal claro.
        - ‚ö†Ô∏è Parcial: interpretaci√≥n indirecta.
        - ‚ùå No validada: sin respaldo.
        """
    )
with st.expander("‚öôÔ∏è ¬øQu√© simula este MVP?"):
    st.markdown(
        """
        1. √Årbol jer√°rquico.
        2. Contexto por nodo.
        3. Fuentes y validaci√≥n.
        4. Exportaci√≥n m√∫ltiple.
        5. Pipeline futuro.
        """
    )
with st.expander("üß† ¬øQu√© es el Reasoning Tracker?"):
    st.markdown(
        """
        - Registro paso a paso.
        - Auditable y exportable.
        """
    )
